# -*- coding: utf-8 -*-
"""Untitled8.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bhXWalsuI5UjZ8lIROx_jOhfQrRVqIbH
"""

listx=[]
listy=[]

# ------------------------------------------------------------------------------
# Copyright (c) Microsoft
# Licensed under the MIT License.
# Written by Bin Xiao (Bin.Xiao@microsoft.com)
# Modified by Xingyi Zhou (zhouxy2017@gmail.com)
# ------------------------------------------------------------------------------
#image.py
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import numpy as np
import cv2


def flip(img):
  return img[:, :, ::-1].copy()  
  
def shuffle_lr(x, shuffle_ref):
  for e in shuffle_ref:
    x[e[0]], x[e[1]] = x[e[1]].copy(), x[e[0]].copy()
  return x


def transform_preds(coords, center, scale, output_size):
    target_coords = np.zeros(coords.shape)
    trans = get_affine_transform(center, scale, 0, output_size, inv=1)
    for p in range(coords.shape[0]):
        target_coords[p, 0:2] = affine_transform(coords[p, 0:2], trans)
    return target_coords


def get_affine_transform(center,
                         scale,
                         rot,
                         output_size,
                         shift=np.array([0, 0], dtype=np.float32),
                         inv=0):
    if not isinstance(scale, np.ndarray) and not isinstance(scale, list):
        scale = np.array([scale, scale])

    scale_tmp = scale
    src_w = scale_tmp[0]
    dst_w = output_size[0]
    dst_h = output_size[1]

    rot_rad = np.pi * rot / 180
    src_dir = get_dir([0, src_w * -0.5], rot_rad)
    dst_dir = np.array([0, dst_w * -0.5], np.float32)

    src = np.zeros((3, 2), dtype=np.float32)
    dst = np.zeros((3, 2), dtype=np.float32)
    src[0, :] = center + scale_tmp * shift
    src[1, :] = center + src_dir + scale_tmp * shift
    dst[0, :] = [dst_w * 0.5, dst_h * 0.5]
    dst[1, :] = np.array([dst_w * 0.5, dst_h * 0.5]) + dst_dir

    src[2:, :] = get_3rd_point(src[0, :], src[1, :])
    dst[2:, :] = get_3rd_point(dst[0, :], dst[1, :])

    if inv:
        trans = cv2.getAffineTransform(np.float32(dst), np.float32(src))
    else:
        trans = cv2.getAffineTransform(np.float32(src), np.float32(dst))

    return trans


def affine_transform(pt, t):
    new_pt = np.array([pt[0], pt[1], 1.]).T
    new_pt = np.dot(t, new_pt)
    return new_pt[:2]


def get_3rd_point(a, b):
    direct = a - b
    return b + np.array([-direct[1], direct[0]], dtype=np.float32)


def get_dir(src_point, rot_rad):
    sn, cs = np.sin(rot_rad), np.cos(rot_rad)

    src_result = [0, 0]
    src_result[0] = src_point[0] * cs - src_point[1] * sn
    src_result[1] = src_point[0] * sn + src_point[1] * cs

    return src_result


def crop(img, center, scale, output_size, rot=0):
    trans = get_affine_transform(center, scale, rot, output_size)

    dst_img = cv2.warpAffine(img,
                             trans,
                             (int(output_size[0]), int(output_size[1])),
                             flags=cv2.INTER_LINEAR)

    return dst_img

def gaussian2D(shape, sigma=1):
    m, n = [(ss - 1.) / 2. for ss in shape]
    y, x = np.ogrid[-m:m+1,-n:n+1]

    h = np.exp(-(x * x + y * y) / (2 * sigma * sigma))
    h[h < np.finfo(h.dtype).eps * h.max()] = 0
    return h

def draw_gaussian(heatmap, center, sigma):
  tmp_size = sigma * 3
  mu_x = int(center[0] + 0.5)
  mu_y = int(center[1] + 0.5)
  w, h = heatmap.shape[0], heatmap.shape[1]
  ul = [int(mu_x - tmp_size), int(mu_y - tmp_size)]
  br = [int(mu_x + tmp_size + 1), int(mu_y + tmp_size + 1)]
  if ul[0] >= h or ul[1] >= w or br[0] < 0 or br[1] < 0:
    return heatmap
  size = 2 * tmp_size + 1
  x = np.arange(0, size, 1, np.float32)
  y = x[:, np.newaxis]
  x0 = y0 = size // 2
  g = np.exp(- ((x - x0) ** 2 + (y - y0) ** 2) / (2 * sigma ** 2))
  g_x = max(0, -ul[0]), min(br[0], h) - ul[0]
  g_y = max(0, -ul[1]), min(br[1], w) - ul[1]
  img_x = max(0, ul[0]), min(br[0], h)
  img_y = max(0, ul[1]), min(br[1], w)
  try:
    heatmap[img_y[0]:img_y[1], img_x[0]:img_x[1]] = np.maximum(
      heatmap[img_y[0]:img_y[1], img_x[0]:img_x[1]],
      g[g_y[0]:g_y[1], g_x[0]:g_x[1]])
  except:
    print('center', center)
    print('gx, gy', g_x, g_y)
    print('img_x, img_y', img_x, img_y)
  return heatmap

def adjust_aspect_ratio(s, aspect_ratio, fit_short_side=False):
  w, h = s[0], s[1]
  if w > aspect_ratio * h:
    if fit_short_side:
      w = h * aspect_ratio
    else:
      h = w * 1.0 / aspect_ratio
  elif w < aspect_ratio * h:
    if fit_short_side:
      h = w * 1.0 / aspect_ratio
    else:
      w = h * aspect_ratio
  return np.array([w, h])

from google.colab import drive
drive.mount('/content/drive')

# eval.py
import numpy as np

def get_preds(hm, return_conf=False):
  assert len(hm.shape) == 4, 'Input must be a 4-D tensor'
  h = hm.shape[2]
  w = hm.shape[3]
  hm = hm.reshape(hm.shape[0], hm.shape[1], hm.shape[2] * hm.shape[3])
  idx = np.argmax(hm, axis = 2)
  
  preds = np.zeros((hm.shape[0], hm.shape[1], 2))
  for i in range(hm.shape[0]):
    for j in range(hm.shape[1]):
      preds[i, j, 0], preds[i, j, 1] = idx[i, j] % w, idx[i, j] / w
  if return_conf:
    conf = np.amax(hm, axis = 2).reshape(hm.shape[0], hm.shape[1], 1)
    return preds, conf
  else:
    return preds

def calc_dists(preds, gt, normalize):
  dists = np.zeros((preds.shape[1], preds.shape[0]))
  for i in range(preds.shape[0]):
    for j in range(preds.shape[1]):
      if gt[i, j, 0] > 0 and gt[i, j, 1] > 0:
        dists[j][i] = \
          ((gt[i][j] - preds[i][j]) ** 2).sum() ** 0.5 / normalize[i]
      else:
        dists[j][i] = -1
  return dists

def dist_accuracy(dist, thr=0.5):
  dist = dist[dist != -1]
  if len(dist) > 0:
    return 1.0 * (dist < thr).sum() / len(dist)
  else:
    return -1

def accuracy(output, target, acc_idxs):
  preds = get_preds(output)
  gt = get_preds(target)
  dists = calc_dists(preds, gt, np.ones(target.shape[0]) * target.shape[2] / 10)
  acc = np.zeros(len(acc_idxs))
  avg_acc = 0
  bad_idx_count = 0
  
  for i in range(len(acc_idxs)):
    acc[i] = dist_accuracy(dists[acc_idxs[i]])
    if acc[i] >= 0:
      avg_acc = avg_acc + acc[i]
    else:
      bad_idx_count = bad_idx_count + 1
  
  if bad_idx_count == len(acc_idxs):
    return 0
  else:
    return avg_acc / (len(acc_idxs) - bad_idx_count)

def get_preds_3d(heatmap, depthmap):
  output_res = max(heatmap.shape[2], heatmap.shape[3])
  preds = get_preds(heatmap).astype(np.int32)
  preds_3d = np.zeros((preds.shape[0], preds.shape[1], 3), dtype=np.float32)
  for i in range(preds.shape[0]):
    for j in range(preds.shape[1]):
      idx = min(j, depthmap.shape[1] - 1)
      pt = preds[i, j]
      preds_3d[i, j, 2] = depthmap[i, idx, pt[1], pt[0]]
      preds_3d[i, j, :2] = 1.0 * preds[i, j] / output_res
    preds_3d[i] = preds_3d[i] - preds_3d[i, 6:7]
  return preds_3d


def mpjpe(heatmap, depthmap, gt_3d, convert_func):
  preds_3d = get_preds_3d(heatmap, depthmap)
  cnt, pjpe = 0, 0
  for i in range(preds_3d.shape[0]):
    if gt_3d[i].sum() ** 2 > 0:
      cnt += 1
      pred_3d_h36m = convert_func(preds_3d[i])
      err = (((gt_3d[i] - pred_3d_h36m) ** 2).sum(axis=1) ** 0.5).mean()
      pjpe += err
  if cnt > 0:
    pjpe /= cnt
  return pjpe, cnt

#debugger.py
import numpy as np
import cv2
import matplotlib.pyplot as plt
import mpl_toolkits.mplot3d
from mpl_toolkits.mplot3d import Axes3D

def show_2d(img, points, c, edges):
  num_joints = points.shape[0]
  points = ((points.reshape(num_joints, -1))).astype(np.int32)
  for j in range(num_joints):
    cv2.circle(img, (points[j, 0], points[j, 1]), 3, c, -1)
  for e in edges:
    if points[e].min() > 0:
      cv2.line(img, (points[e[0], 0], points[e[0], 1]),
                    (points[e[1], 0], points[e[1], 1]), c, 2)
  return img

mpii_edges = [[0, 1], [1, 2], [2, 6], [6, 3], [3, 4], [4, 5], 
              [10, 11], [11, 12], [12, 8], [8, 13], [13, 14], [14, 15], 
              [6, 8], [8, 9]]

class Debugger(object):
  def __init__(self, ipynb=False, edges=mpii_edges):
    self.ipynb = ipynb
    if not self.ipynb:
      self.plt = plt
      self.fig = self.plt.figure()
      self.ax = self.fig.add_subplot((111),projection='3d')
      self.ax.grid(False)
    oo = 1e10
    self.xmax, self.ymax, self.zmax = -oo, -oo, -oo
    self.xmin, self.ymin, self.zmin = oo, oo, oo
    self.imgs = {}
    self.edges=edges
    

  
  def add_point_3d(self, points, c='b', marker='o', edges=None):
    if edges == None:
      edges = self.edges
    #show3D(self.ax, point, c, marker = marker, edges)
    points = points.reshape(-1, 3)
    x, y, z = np.zeros((3, points.shape[0]))
    for j in range(points.shape[0]):
      x[j] = points[j, 0].copy()
      y[j] = points[j, 2].copy()
      z[j] = - points[j, 1].copy()
      self.xmax = max(x[j], self.xmax)
      self.ymax = max(y[j], self.ymax)
      self.zmax = max(z[j], self.zmax)
      self.xmin = min(x[j], self.xmin)
      self.ymin = min(y[j], self.ymin)
      self.zmin = min(z[j], self.zmin)
    if c == 'auto':
      c = [(z[j] + 0.5, y[j] + 0.5, x[j] + 0.5) for j in range(points.shape[0])]
    self.ax.scatter(x, y, z, s = 200, c = c, marker = marker)
    for e in edges:
      self.ax.plot(x[e], y[e], z[e], c = c)
    
  def show_3d(self):
    max_range = np.array([self.xmax-self.xmin, self.ymax-self.ymin, self.zmax-self.zmin]).max()
    Xb = 0.5*max_range*np.mgrid[-1:2:2,-1:2:2,-1:2:2][0].flatten() + 0.5*(self.xmax+self.xmin)
    Yb = 0.5*max_range*np.mgrid[-1:2:2,-1:2:2,-1:2:2][1].flatten() + 0.5*(self.ymax+self.ymin)
    Zb = 0.5*max_range*np.mgrid[-1:2:2,-1:2:2,-1:2:2][2].flatten() + 0.5*(self.zmax+self.zmin)
    for xb, yb, zb in zip(Xb, Yb, Zb):
      self.ax.plot([xb], [yb], [zb], 'w')
    self.plt.show()
    
  def add_img(self, img, imgId = 'default'):
    self.imgs[imgId] = img.copy()
  
  def add_mask(self, mask, bg, imgId = 'default', trans = 0.8):
    self.imgs[imgId] = (mask.reshape(mask.shape[0], mask.shape[1], 1) * 255 * trans + \
                        bg * (1 - trans)).astype(np.uint8)

  def add_point_2d(self, point, c, imgId='default'):
    self.imgs[imgId] = show_2d(self.imgs[imgId], point, c, self.edges)
  
  def show_img(self, pause = False, imgId = 'default'):

    cv2.imshow('{}'.format(imgId), self.imgs[imgId])
    
    if pause:
      cv2.waitKey()
  
  def show_all_imgs(self, pause = False):
    if not self.ipynb:
      for i, v in self.imgs.items():
        # cv2.imshow('{}'.format(i), v)
        cv2.imwrite('/content/drive/MyDrive/cv_project/debug/a.jpg',v)
      if pause:
        cv2.waitKey()
    else:
      self.ax = None
      nImgs = len(self.imgs)
      fig=plt.figure(figsize=(nImgs * 10,10))
      nCols = nImgs
      nRows = nImgs // nCols
      for i, (k, v) in enumerate(self.imgs.items()):
        fig.add_subplot(1, nImgs, i + 1)
        if len(v.shape) == 3:
          plt.imshow(cv2.cvtColor(v, cv2.COLOR_BGR2RGB))
        else:
          plt.imshow(v)
      plt.show()
  
  def save_3d(self, path):
    max_range = np.array([self.xmax-self.xmin, self.ymax-self.ymin, self.zmax-self.zmin]).max()
    Xb = 0.5*max_range*np.mgrid[-1:2:2,-1:2:2,-1:2:2][0].flatten() + 0.5*(self.xmax+self.xmin)
    Yb = 0.5*max_range*np.mgrid[-1:2:2,-1:2:2,-1:2:2][1].flatten() + 0.5*(self.ymax+self.ymin)
    Zb = 0.5*max_range*np.mgrid[-1:2:2,-1:2:2,-1:2:2][2].flatten() + 0.5*(self.zmax+self.zmin)
    for xb, yb, zb in zip(Xb, Yb, Zb):
      self.ax.plot([xb], [yb], [zb], 'w')
    self.plt.savefig(path, bbox_inches='tight', frameon = False)
  
  def save_img(self, imgId = 'default', path = 'debug/',file_name='default'):
    # listx.append(self.imgs[imgId])
    # listy.append(1)
    cv2.imwrite(path + file_name +'.png', self.imgs[imgId])
    
  # def save_all_imgs(self, path = 'debug/'):
  #   print(self.imgs.items)
  #   d=0
  #   for i, v in self.imgs.items():
  #     filename = "debug/file_%d.png" %d
  #     cv2.imwrite(filename, v)
  #     v+=1
  #     d+=1

# ------------------------------------------------------------------------------
# Copyright (c) Microsoft
# Licensed under the MIT License.
# Written by Bin Xiao (Bin.Xiao@microsoft.com)
# Modified by Xingyi Zhou
# ------------------------------------------------------------------------------
#msra_rsnet.py
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import os

import torch
import torch.nn as nn
import torch.utils.model_zoo as model_zoo

BN_MOMENTUM = 0.1

model_urls = {
    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',
    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',
    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',
    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',
    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',
}

def conv3x3(in_planes, out_planes, stride=1):
    """3x3 convolution with padding"""
    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,
                     padding=1, bias=False)


class BasicBlock(nn.Module):
    expansion = 1

    def __init__(self, inplanes, planes, stride=1, downsample=None):
        super(BasicBlock, self).__init__()
        self.conv1 = conv3x3(inplanes, planes, stride)
        self.bn1 = nn.BatchNorm2d(planes, momentum=BN_MOMENTUM)
        self.relu = nn.ReLU(inplace=True)
        self.conv2 = conv3x3(planes, planes)
        self.bn2 = nn.BatchNorm2d(planes, momentum=BN_MOMENTUM)
        self.downsample = downsample
        self.stride = stride

    def forward(self, x):
        residual = x

        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)

        out = self.conv2(out)
        out = self.bn2(out)

        if self.downsample is not None:
            residual = self.downsample(x)

        out += residual
        out = self.relu(out)

        return out


class Bottleneck(nn.Module):
    expansion = 4

    def __init__(self, inplanes, planes, stride=1, downsample=None):
        super(Bottleneck, self).__init__()
        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)
        self.bn1 = nn.BatchNorm2d(planes, momentum=BN_MOMENTUM)
        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,
                               padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(planes, momentum=BN_MOMENTUM)
        self.conv3 = nn.Conv2d(planes, planes * self.expansion, kernel_size=1,
                               bias=False)
        self.bn3 = nn.BatchNorm2d(planes * self.expansion,
                                  momentum=BN_MOMENTUM)
        self.relu = nn.ReLU(inplace=True)
        self.downsample = downsample
        self.stride = stride

    def forward(self, x):
        residual = x

        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)

        out = self.conv2(out)
        out = self.bn2(out)
        out = self.relu(out)

        out = self.conv3(out)
        out = self.bn3(out)

        if self.downsample is not None:
            residual = self.downsample(x)

        out += residual
        out = self.relu(out)

        return out


class PoseResNet(nn.Module):

    def __init__(self, block, layers, heads, **kwargs):
        self.inplanes = 64
        self.deconv_with_bias = False
        self.heads = heads

        super(PoseResNet, self).__init__()
        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,
                               bias=False)
        self.bn1 = nn.BatchNorm2d(64, momentum=BN_MOMENTUM)
        self.relu = nn.ReLU(inplace=True)
        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
        self.layer1 = self._make_layer(block, 64, layers[0])
        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)
        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)
        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)

        # used for deconv layers
        self.deconv_layers = self._make_deconv_layer(
            3,
            [256, 256, 256],
            [4, 4, 4],
        )
        # self.final_layer = []

        for head in sorted(self.heads):
          num_output = self.heads[head]
          self.__setattr__(head, nn.Conv2d(
              in_channels=256,
              out_channels=num_output,
              kernel_size=1,
              stride=1,
              padding=0
          ))

        # self.final_layer = nn.ModuleList(self.final_layer)

    def _make_layer(self, block, planes, blocks, stride=1):
        downsample = None
        if stride != 1 or self.inplanes != planes * block.expansion:
            downsample = nn.Sequential(
                nn.Conv2d(self.inplanes, planes * block.expansion,
                          kernel_size=1, stride=stride, bias=False),
                nn.BatchNorm2d(planes * block.expansion, momentum=BN_MOMENTUM),
            )

        layers = []
        layers.append(block(self.inplanes, planes, stride, downsample))
        self.inplanes = planes * block.expansion
        for i in range(1, blocks):
            layers.append(block(self.inplanes, planes))

        return nn.Sequential(*layers)

    def _get_deconv_cfg(self, deconv_kernel, index):
        if deconv_kernel == 4:
            padding = 1
            output_padding = 0
        elif deconv_kernel == 3:
            padding = 1
            output_padding = 1
        elif deconv_kernel == 2:
            padding = 0
            output_padding = 0

        return deconv_kernel, padding, output_padding

    def _make_deconv_layer(self, num_layers, num_filters, num_kernels):
        assert num_layers == len(num_filters), \
            'ERROR: num_deconv_layers is different len(num_deconv_filters)'
        assert num_layers == len(num_kernels), \
            'ERROR: num_deconv_layers is different len(num_deconv_filters)'

        layers = []
        for i in range(num_layers):
            kernel, padding, output_padding = \
                self._get_deconv_cfg(num_kernels[i], i)

            planes = num_filters[i]
            layers.append(
                nn.ConvTranspose2d(
                    in_channels=self.inplanes,
                    out_channels=planes,
                    kernel_size=kernel,
                    stride=2,
                    padding=padding,
                    output_padding=output_padding,
                    bias=self.deconv_with_bias))
            layers.append(nn.BatchNorm2d(planes, momentum=BN_MOMENTUM))
            layers.append(nn.ReLU(inplace=True))
            self.inplanes = planes

        return nn.Sequential(*layers)

    def forward(self, x):
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.maxpool(x)

        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.layer4(x)

        x = self.deconv_layers(x)
        ret = {}
        for head in self.heads:
            ret[head] = self.__getattr__(head)(x)
        return [ret]

    def init_weights(self, num_layers, pretrained=True):
        if pretrained:
            # print('=> init resnet deconv weights from normal distribution')
            for _, m in self.deconv_layers.named_modules():
                if isinstance(m, nn.ConvTranspose2d):
                    # print('=> init {}.weight as normal(0, 0.001)'.format(name))
                    # print('=> init {}.bias as 0'.format(name))
                    nn.init.normal_(m.weight, std=0.001)
                    if self.deconv_with_bias:
                        nn.init.constant_(m.bias, 0)
                elif isinstance(m, nn.BatchNorm2d):
                    # print('=> init {}.weight as 1'.format(name))
                    # print('=> init {}.bias as 0'.format(name))
                    nn.init.constant_(m.weight, 1)
                    nn.init.constant_(m.bias, 0)
            # print('=> init final conv weights from normal distribution')
            for head in self.heads:
              final_layer = self.__getattr__(head)
              for m in final_layer.modules():
                  if isinstance(m, nn.Conv2d):
                      # nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
                      # print('=> init {}.weight as normal(0, 0.001)'.format(head))
                      # print('=> init {}.bias as 0'.format(name))
                      nn.init.normal_(m.weight, std=0.001)
                      nn.init.constant_(m.bias, 0)
            #pretrained_state_dict = torch.load(pretrained)
            url = model_urls['resnet{}'.format(num_layers)]
            pretrained_state_dict = model_zoo.load_url(url)
            print('=> loading pretrained model {}'.format(url))
            self.load_state_dict(pretrained_state_dict, strict=False)
        else:
            print('=> imagenet pretrained model dose not exist')
            print('=> please download it first')
            raise ValueError('imagenet pretrained model does not exist')


resnet_spec = {18: (BasicBlock, [2, 2, 2, 2]),
               34: (BasicBlock, [3, 4, 6, 3]),
               50: (Bottleneck, [3, 4, 6, 3]),
               101: (Bottleneck, [3, 4, 23, 3]),
               152: (Bottleneck, [3, 8, 36, 3])}


def get_pose_net(num_layers, heads):
  block_class, layers = resnet_spec[num_layers]

  model = PoseResNet(block_class, layers, heads)
  model.init_weights(num_layers, pretrained=True)
  return model

#model.py
import torchvision.models as models
import torch
import torch.nn as nn
import os

# from models.msra_resnet import get_pose_net

def create_model(opt): 
  if 'msra' in opt.arch:
    print("=> using msra resnet '{}'".format(opt.arch))
    num_layers = int(opt.arch[opt.arch.find('_') + 1:])
    model = get_pose_net(num_layers, opt.heads)
    optimizer = torch.optim.Adam(model.parameters(), opt.lr)
  else:
    assert 0, "Model not supported!"
    
  start_epoch = 1
  if opt.load_model != '':
    checkpoint = torch.load(opt.load_model)
    print('loaded {}, epoch {}'.format(opt.load_model, checkpoint['epoch']))
    if type(checkpoint) == type({}):
      state_dict = checkpoint['state_dict']
    else:
      state_dict = checkpoint.state_dict()
    model.load_state_dict(state_dict, strict=False)
    if opt.resume:
      print('resuming optimizer')
      optimizer.load_state_dict(checkpoint['optimizer'])
      start_epoch = checkpoint['epoch'] + 1
      for state in optimizer.state.values():
        for k, v in state.items():
          if isinstance(v, torch.Tensor):
            state[k] = v.cuda(opt.device, non_blocking=True)

  return model, optimizer, start_epoch
  
def save_model(path, epoch, model, optimizer=None):
  if isinstance(model, torch.nn.DataParallel):
    state_dict = model.module.state_dict()
  else:
    state_dict = model.state_dict()
  data = {'epoch': epoch,
          'state_dict': state_dict}
  if not (optimizer is None):
    data['optimizer'] = optimizer.state_dict()
  torch.save(data, path)

#opts.py
import argparse
import os
import sys

class opts():
  def __init__(self):
    self.parser = argparse.ArgumentParser()

    self.parser.add_argument('--exp_id', default = 'default')
    self.parser.add_argument('--gpus', default='0', help='-1 for CPU')
    self.parser.add_argument('--num_workers', type=int, default=4)
    self.parser.add_argument('--test', action = 'store_true', help = 'test')
    self.parser.add_argument('--debug', type = int, default = 0)
    self.parser.add_argument('--demo', default = '/content/drive/MyDrive/cv_project/resized/jumpingjacks', help = 'path/to/image')

    self.parser.add_argument('--task', default='human2d')
    self.parser.add_argument('--ratio_3d', type=float, default=0)
    self.parser.add_argument('--weight_3d', type=float, default=0)
    self.parser.add_argument('--weight_var', type=float, default=0)
    self.parser.add_argument('--full_test', action='store_true')


    self.parser.add_argument('--hide_data_time', action = 'store_true')
    self.parser.add_argument('--metric', default = 'acc')
    self.parser.add_argument('--resume', action = 'store_true')
    self.parser.add_argument('--load_model', default = '')
    self.parser.add_argument('--weight_decay', type=float, default=0.0)
    self.parser.add_argument('--scale', type=float, default=-1)
    self.parser.add_argument('--rotate', type=float, default=-1)
    self.parser.add_argument('--flip', type = float, default=0.5)
    self.parser.add_argument('--dataset', default = 'mpii', 
                             help = 'mpii | coco')
    self.parser.add_argument('--all_pts', action = 'store_true',
                             help = 'heatmap for all persons in stack 1')
    self.parser.add_argument('--multi_person', action = 'store_true', 
                             help = 'heatmap for all persons in final stack')
    self.parser.add_argument('--fit_short_side', action = 'store_true', 
                             help = 'fit to long or short bbox side when'
                                    'the input resolution is rectangle')
    self.parser.add_argument('--lr', type=float, default=0.001)
    self.parser.add_argument('--lr_step', type=str, default='90,120')
    self.parser.add_argument('--num_epochs', type=int, default=140)
    self.parser.add_argument('--val_intervals', type=int, default=5)
    self.parser.add_argument('--batch_size', type=int, default=32)
    self.parser.add_argument('--arch', default = 'msra_50', 
                             help = 'hg | msra_xxx')
    self.parser.add_argument('--disable_cudnn', action = 'store_true')
    self.parser.add_argument('--save_all_models', action = 'store_true')
    self.parser.add_argument('--print_iter', type = int, default = -1, 
                             help = 'for run in cloud server')

    self.parser.add_argument('--input_h', type = int, default = -1)
    self.parser.add_argument('--input_w', type = int, default = -1)
    self.parser.add_argument('--output_h', type = int, default = -1)
    self.parser.add_argument('--output_w', type = int, default = -1)

  def parse(self, args = ''):
    if args == '':
      opt = self.parser.parse_args([])
    else:
      opt = self.parser.parse_args(args)
    
    opt.eps = 1e-6
    opt.momentum = 0.0
    opt.alpha = 0.99
    opt.epsilon = 1e-8
    opt.hm_gauss = 2
    # opt.root_dir = os.path.join(os.path.dirname(__file__), '..', '..')
    # opt.data_dir = os.path.join(opt.root_dir, 'data')
    # opt.exp_dir = os.path.join(opt.root_dir, 'exp')

    # opt.save_dir = os.path.join(opt.exp_dir, opt.exp_id)
    if opt.debug > 0:
      opt.num_workers = 1

    opt.gpus = [int(gpu) for gpu in opt.gpus.split(',')]
    opt.lr_step = [int(i) for i in opt.lr_step.split(',')]
    if opt.test:
      opt.exp_id = opt.exp_id + 'TEST'
    #opt.save_dir = os.path.join(opt.exp_dir, opt.exp_id)

    if 'hg' in opt.arch or 'posenet' in opt.arch:
      opt.num_stacks = 2
    else:
      opt.num_stacks = 1
    
    if opt.input_h == -1 and opt.input_w == -1 and \
      opt.output_h == -1 and opt.output_w == -1:
      if opt.dataset == 'coco':
        opt.input_h, opt.input_w = 256, 192
        opt.output_h, opt.output_w = 64, 48
      else:
        opt.input_h, opt.input_w = 256, 256
        opt.output_h, opt.output_w = 64, 64
    else:
      assert opt.input_h // opt.output_h == opt.input_w // opt.output_w
    
    if opt.scale == -1:
      opt.scale = 0.3 if opt.dataset == 'coco' else 0.25
    if opt.rotate == -1:
      opt.rotate = 40 if opt.dataset == 'coco' else 30

    opt.num_output = 17 if opt.dataset == 'coco' else 16
    opt.num_output_depth = opt.num_output if opt.task == 'human3d' else 0
    opt.heads = {'hm': opt.num_output}
    if opt.num_output_depth > 0:
      opt.heads['depth'] = opt.num_output_depth
    print('heads', opt.heads)


    if opt.resume:
      opt.load_model = '/content/drive/MyDrive/cv_project/fusion_3d_var.pth'

    return opt

# #init_path.py
# import os.path as osp
# import sys

# def add_path(path):
#     if path not in sys.path:
#         sys.path.insert(0, path)

# this_dir = osp.dirname(__file__)

# # Add lib to PYTHONPATH
# lib_path = osp.join(this_dir, 'lib')
# add_path(lib_path)

key_points=[]

#demo.py
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
from os import listdir
import os

# import _init_paths

import os

import cv2
import numpy as np
import torch
import torch.utils.data
# from opts import opts
# from model import create_model
# from debugger import Debugger
# from utils.image import get_affine_transform, transform_preds
# from utils.eval import get_preds, get_preds_3d
image_ext = ['jpg', 'jpeg', 'png']
mean = np.array([0.485, 0.456, 0.406], np.float32).reshape(1, 1, 3)
std = np.array([0.229, 0.224, 0.225], np.float32).reshape(1, 1, 3)

def is_image(file_name):
  ext = file_name[file_name.rfind('.') + 1:].lower()
  return ext in image_ext


def demo_image(image, model, opt,file_name):
  s = max(image.shape[0], image.shape[1]) * 1.0
  c = np.array([image.shape[1] / 2., image.shape[0] / 2.], dtype=np.float32)
  trans_input = get_affine_transform(
      c, s, 0, [opt.input_w, opt.input_h])
  inp = cv2.warpAffine(image, trans_input, (opt.input_w, opt.input_h),
                         flags=cv2.INTER_LINEAR)
  inp = (inp / 255. - mean) / std
  inp = inp.transpose(2, 0, 1)[np.newaxis, ...].astype(np.float32)
  inp = torch.from_numpy(inp).to(opt.device)
  out = model(inp)[-1]
  pred = get_preds(out['hm'].detach().cpu().numpy())[0]
  
  pred = transform_preds(pred, c, s, (opt.output_w, opt.output_h))
  key_points.append(pred)
  pred_3d = get_preds_3d(out['hm'].detach().cpu().numpy(), 
                         out['depth'].detach().cpu().numpy())[0]
  
  debugger = Debugger()
  debugger.add_img(image)
  debugger.add_point_2d(pred, (255, 0, 0))
  debugger.add_point_3d(pred_3d, 'b')
  debugger.show_all_imgs(pause=False)
  debugger.show_3d()
  # debugger.save_all_imgs()
  print(file_name)
  x=file_name.split('.')
  debugger.save_img('default','debug/',file_name)

def main(opt):
  opt.heads['depth'] = opt.num_output
  if opt.load_model == '':
    opt.load_model = '/content/drive/MyDrive/cv_project/fusion_3d_var.pth'
  if opt.gpus[0] >= 0:
    opt.device = torch.device('cuda:{}'.format(opt.gpus[0]))
  else:
    opt.device = torch.device('cpu')
  
  model, _, _ = create_model(opt)
  model = model.to(opt.device)
  model.eval()
  print('Finished creating model')
  count=0
  for path in listdir(opt.demo):
    # check if current path is a file
    if os.path.isfile(os.path.join(opt.demo, path)):
        count += 1

  if os.path.isdir(opt.demo):
    ls = os.listdir(opt.demo)

    for i in range(count):
    # inp=cv2.imread('crunches/x%d.jpg' %i)
    # masking=cv2.imread('test_output_crunches/x%d.jpg' %i)
    # inp=cv2.imread('jumpingjacks/x%d.jpg' %i)
    # masking=cv2.imread('test_output_jumppingjacks1/x%d.jpg' %i)
    

    # for file_name in sorted(ls):
    #   if is_image(file_name):
        # image_name = os.path.join(opt.demo, file_name)
        # print('Running {} ...'.format(image_name))
        image=cv2.imread(os.path.join(opt.demo,'x%d.jpg' %i))
        # image = cv2.imread(image_name)
        # print(type(image), image.shape)
        demo_image(image, model, opt,'x%d.jpg' %i)
  # elif is_image(opt.demo):
  #   print('Running {} ...'.format(opt.demo))
  #   image = cv2.imread(opt.demo)
  #   demo_image(image, model, opt)
    


opt = opts().parse()
main(opt)

points=np.array(key_points)
# np.save('key_points',key_points)

points.shape

np.save('keypoints',points)

x=np.array(listx)

x.shape

x=np.array(listx)

import numpy as np
import cv2
from os import listdir
import os
import pickle
image_directory1='/content/drive/MyDrive/cv_project/new_pushups'
image_directory2='/content/drive/MyDrive/cv_project/foreground_crunches'
image_directory3='/content/drive/MyDrive/cv_project/foreground_jumpingjacks1'
image_directory4='/content/drive/MyDrive/cv_project/foreground_jumpingjacks2'
count=0
listx=[]
listy=[]
for file in listdir(image_directory1):
    # check if current path is a file
    image = cv2.imread(os.path.join(image_directory1, file))
    listx.append(image)
    listy.append(0)

for file in listdir(image_directory2):
    # check if current path is a file
    image = cv2.imread(os.path.join(image_directory2, file))
    listx.append(image)
    listy.append(1)

for file in listdir(image_directory3):
    # check if current path is a file
    image = cv2.imread(os.path.join(image_directory3, file))
    listx.append(image)
    listy.append(2)

for file in listdir(image_directory4):
    # check if current path is a file
    image = cv2.imread(os.path.join(image_directory4, file))
    listx.append(image)
    listy.append(2)
x=np.array(listx)
y=np.array(listy)
print(x.shape)
print(y.shape)
# pickle.dump(x, open("x.pkl", "w"))
# pickle.dump(y,open("y.pkl", "w"))